
# ğŸ“¦ Projeto ETL com Python, Pandas e PostgreSQL

![ETL Pipeline](./assets/etl_pipeline.png)

Este projeto implementa um pipeline de ETL (Extract, Transform, Load) simples e eficaz utilizando Python, a biblioteca Pandas e o banco de dados PostgreSQL. O objetivo Ã© ler mÃºltiplos arquivos CSV, transformÃ¡-los em DataFrames e carregÃ¡-los como tabelas no banco de dados, substituindo qualquer tabela existente.

---

## ğŸš€ Tecnologias Utilizadas

- **Python 3.10+**
- **Pandas**
- **SQLAlchemy**
- **PostgreSQL**
- **psycopg2**

---

## ğŸ“Œ Funcionalidades

- ğŸ”„ Leitura automÃ¡tica de mÃºltiplos arquivos `.csv`
- ğŸ›  TransformaÃ§Ã£o (simples) usando `pandas`
- ğŸ˜ Carga de dados no banco PostgreSQL
- ğŸ“‚ SubstituiÃ§Ã£o das tabelas caso jÃ¡ existam
- âœ… Projeto pronto para expandir com tratamento de erros e validaÃ§Ãµes

---

## ğŸ“ Estrutura de Pastas

```
â”œâ”€â”€ csv_files/
â”‚   â”œâ”€â”€ itens_pedido.csv
â”‚   â””â”€â”€ pedidos.csv
â”œâ”€â”€ etl_script.py
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ etl_pipeline.png
â”‚   â””â”€â”€ e_shop_DER.png
â”œâ”€â”€ ddl_database/
â”‚   â””â”€â”€ ddl.sql
â”œâ”€â”€ README.md
```

---

## âš™ï¸ Como Executar

### 1. Clone o repositÃ³rio
```bash
git clone https://github.com/DilleyAndrade/ETL-com-Python-Pandas-e-PostgreSQL.git
cd ETL-com-Python-Pandas-e-PostgreSQL
```

### 2. Crie um ambiente virtual (opcional, mas recomendado)
```bash
python -m venv venv
source venv/bin/activate  # Linux/macOS
venv\Scripts\activate     # Windows
```

### 3. Instale as dependÃªncias
```bash
pip install -r requirements.txt
```

**Ou instale manualmente:**
```bash
pip install pandas sqlalchemy psycopg2-binary
```

### 4. Configure seu banco de dados

Certifique-se de que seu banco PostgreSQL esteja ativo e configurado com:
- host: `seu localhost`
- port: `sua porta`
- user: `seu usuÃ¡rio`
- password: `sua senha`
- database: `seu banco de dados`

VocÃª pode modificar essas configuraÃ§Ãµes diretamente no `etl_script.py`.

### 5. Execute o script
```bash
python etl_script.py
```

---

## ğŸ§ª Exemplo de CÃ³digo Principal

```python
files_list = ['itens_pedido', 'pedidos']

def etl_data():
    for file in files_list:
        df = pd.read_csv(f"csv_files/{file}.csv")
        df.to_sql(f'{file}', con=engine, schema='public', if_exists='replace', index=False)
        print(f'Table {file} saved!')

etl_data()
```

---

## ğŸ“ˆ Pipeline do Projeto

A imagem abaixo representa o pipeline ETL deste projeto:

```
[CSV Files] â†’ [TransformaÃ§Ãµes com Pandas] â†’ [Carga no PostgreSQL]
```

> ![ETL Pipeline](./assets/etl_pipeline.png)

---

## ğŸ”’ SeguranÃ§a

> âš ï¸ **Evite hardcoding de credenciais em produÃ§Ã£o!**
- Utilize variÃ¡veis de ambiente (`os.environ`) ou bibliotecas como `python-dotenv`.

---

## ğŸ“Œ PossÃ­veis ExpansÃµes

- ValidaÃ§Ã£o de schema dos arquivos
- Logging detalhado
- Testes automatizados com `pytest`
- Interface CLI com `argparse` ou `click`
- Dashboard simples com `Streamlit` ou `Flask`

---

## ğŸ‘¨â€ğŸ’» Autor

Dilley Andrade
Engenheiro de Dados | SQL | ETL | Python â€” Focado em soluÃ§Ãµes de dados, ETL, BI e engenharia de dados.
(81) 98663-2609 | dilleyandrade@gmail.com |
http://linkedin.com/in/dilleyandrade | http://github.com/DilleyAndrade 

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Consulte o arquivo `LICENSE` para mais detalhes.
